{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import mpl_toolkits\n",
    "# from mpl_toolkits import mplot3d\n",
    "from matplotlib import cm\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.ticker as ticker\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import math\n",
    "import pandas as pd\n",
    "import os\n",
    "import itertools\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "class ScalarFormatterForceFormatZero(ticker.ScalarFormatter):\n",
    "    def _set_format(self):  # Override function that finds format to use\n",
    "        self.format = '%1.0f'  # Give format here\n",
    "\n",
    "class ScalarFormatterForceFormatOne(ticker.ScalarFormatter):\n",
    "    def _set_format(self):\n",
    "        self.format = '%1.1f'\n",
    "\n",
    "class ScalarFormatterForceFormat(ticker.ScalarFormatter):\n",
    "    def _set_format(self):\n",
    "        self.format = '%1.2f'\n",
    "        \n",
    "class ScalarFormatterForceFormatThree(ticker.ScalarFormatter):\n",
    "    def _set_format(self):\n",
    "        self.format = '%1.3f'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(os.path.realpath('/Users/wei/Documents/physics/code/tnpy'))\n",
    "sys.path.append(os.path.realpath('/Users/wei/Documents/physics/code/tnpy/tnpy'))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload all\n",
    "\n",
    "import tnpy as tp\n",
    "from tnpy import GTensor\n",
    "from tnpy.mps import FermiMPS as fMPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.19915e+20-13975.93738j) tensor(8.19915e+20+13975.93738j)\n",
      "tensor(2.40315e+20-9.63662e+18j)\n",
      "left inner product: tensor(6.00000+4.60280e-17j)\n",
      "right inner product: tensor(6.00000+2.70483e-16j)\n",
      "Fidelity: tensor(0.00068-5.22973e-21j)\n"
     ]
    }
   ],
   "source": [
    "# our fMPS tensor convention\n",
    "# \n",
    "#  0 --<--*--<-- 1\n",
    "#         ï½œ2\n",
    "#         v\n",
    "\n",
    "gt_dual = (0, 1, 0)\n",
    "gt_shape = ((3, 3), (3, 3), (2, 2))\n",
    "\n",
    "fmps = fMPS.rand(n=16, dual=gt_dual, shape=gt_shape)\n",
    "fmps_dagger = fmps.dagger()\n",
    "print(fmps.inner_product(fmps_dagger, fmps), fmps.inner_product(fmps, fmps_dagger))\n",
    "\n",
    "fmps_0 = fMPS.rand(n=16, dual=gt_dual, shape=gt_shape)\n",
    "print(fmps.inner_product(fmps_0.dagger(), fmps))\n",
    "\n",
    "lc_mps = fmps.left_canonical()\n",
    "rc_mps = fmps.right_canonical()\n",
    "\n",
    "print('left inner product:', fmps.inner_product(lc_mps.dagger(), lc_mps))\n",
    "print('right inner product:', fmps.inner_product(rc_mps.dagger(), rc_mps))\n",
    "\n",
    "print('Fidelity:', fmps.fidelity(lc_mps, rc_mps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1, 1, 0) ((2, 2), (3, 2), (2, 2), (3, 2))\n",
      "((2, 2), (3, 2), (2, 2), (3, 2)) ((2, 2), (3, 2)) (0, 1, 1, 0)\n",
      "(0, 1) ((2, 2), (3, 2)) torch.Size([4, 5])\n",
      "(0, 0, 0, 0)\n",
      "tensor(0.)\n",
      "(0, 0, 1, 1)\n",
      "tensor(0.)\n",
      "(0, 1, 0, 1)\n",
      "tensor(0.)\n",
      "(0, 1, 1, 0)\n",
      "tensor(0.)\n",
      "(1, 0, 0, 1)\n",
      "tensor(0.)\n",
      "(1, 0, 1, 0)\n",
      "tensor(0.)\n",
      "(1, 1, 0, 0)\n",
      "tensor(0.)\n",
      "(1, 1, 1, 1)\n",
      "tensor(0.)\n",
      "20\n",
      "[ 5.07632106+5.49196831j -0.67601621-1.01456099j -1.04004405+0.45859571j]\n",
      "[-1.97989266-0.36706353j -2.89319219-0.19163032j -2.45522401-0.02889539j\n",
      "  0.        +0.j          0.        +0.j         -2.10154421-0.48144266j\n",
      " -2.65997717+0.05430537j -2.01097431-0.78955756j  0.        +0.j\n",
      "  0.        +0.j          0.        +0.j          0.        +0.j\n",
      "  0.        +0.j         -1.88143712-0.67224909j -2.18241112-0.49111602j\n",
      "  0.        +0.j          0.        +0.j          0.        +0.j\n",
      " -2.33671878-0.19570903j -2.52957854-0.3905307j ] [-1.97989266-0.36706353j -2.89319219-0.19163032j -2.45522401-0.02889539j\n",
      "  0.        +0.j          0.        +0.j         -2.10154421-0.48144266j\n",
      " -2.65997717+0.05430537j -2.01097431-0.78955756j  0.        +0.j\n",
      "  0.        +0.j          0.        +0.j          0.        +0.j\n",
      "  0.        +0.j         -1.88143712-0.67224909j -2.18241112-0.49111602j\n",
      "  0.        +0.j          0.        +0.j          0.        +0.j\n",
      " -2.33671878-0.19570903j -2.52957854-0.3905307j ]\n",
      "(0, 0)\n",
      "tensor(2.53975e-15)\n",
      "(1, 1)\n",
      "tensor(3.88707e-15)\n"
     ]
    }
   ],
   "source": [
    "# test GTensor eigen-problem\n",
    "\n",
    "my_dual = (0, 1, 1, 0)\n",
    "my_gds = (0, 1), (2, 3)\n",
    "my_shape = (2, 2), (3, 2), (2, 2), (3, 2)\n",
    "\n",
    "gt = GTensor.rand(dual=my_dual, shape=my_shape, cflag=True)\n",
    "print(gt.dual, gt.shape)\n",
    "\n",
    "dt = gt.push_blocks()\n",
    "v_whole_shape = (dt.shape[2:])\n",
    "v_shape = gt.shape[2:]\n",
    "\n",
    "v_dual = tuple([d ^ 1 for d in gt.dual[2:]])\n",
    "print(gt.shape, v_shape, gt.dual)\n",
    "print(v_dual, v_shape, v_whole_shape)\n",
    "\n",
    "new_gt = GTensor.extract_blocks(dt, gt.dual, gt.shape)\n",
    "\n",
    "for key, val in new_gt.blocks().items():\n",
    "    print(key)\n",
    "    # print(v)\n",
    "    print((val-gt.blocks()[key]).norm())\n",
    "\n",
    "def mv(v):\n",
    "    # covert to torch.tensor\n",
    "    tv = torch.from_numpy(v.reshape(v_whole_shape)).cdouble()\n",
    "    # print(tv.shape)\n",
    "    # build GTensor from dense tensor\n",
    "    gtv = GTensor.extract_blocks(tv, v_dual, v_shape)\n",
    "    # test = gtv.push_blocks()\n",
    "    # print('test', gtv.shape, tv, (test-tv).norm())\n",
    "    w = tp.gcontract('abcd,cd->ab', gt, gtv)\n",
    "\n",
    "    return w.push_blocks().numpy().flatten()\n",
    "\n",
    "# w = mv(v)\n",
    "# print(w.shape)\n",
    "\n",
    "dim_op = math.prod(v_whole_shape)\n",
    "print(dim_op)\n",
    "op = scipy.sparse.linalg.LinearOperator(shape=(dim_op, dim_op), matvec=mv)\n",
    "v_init = GTensor.rand(dual=v_dual, shape=v_shape).push_blocks().numpy().flatten()\n",
    "vals, vecs = scipy.sparse.linalg.eigs(\n",
    "        op, k=3, which='LM', v0=v_init, maxiter=None, return_eigenvectors=True)\n",
    "inds = abs(vals).argsort()[::-1]\n",
    "sorted_vals, sorted_vecs = vals[inds], vecs[:, inds]\n",
    "\n",
    "print(sorted_vals)\n",
    "lam = sorted_vals[0]\n",
    "eig_v = sorted_vecs[:, 0]\n",
    "w = mv(eig_v)\n",
    "print(lam*eig_v, w)\n",
    "\n",
    "eig_vt = torch.from_numpy(eig_v.reshape(v_whole_shape))\n",
    "eig_gvt = GTensor.extract_blocks(eig_vt, v_dual, v_shape)\n",
    "\n",
    "right = lam*eig_gvt\n",
    "left = tp.gcontract('abcd,cd->ab', gt, eig_gvt)\n",
    "\n",
    "for key, val in right.blocks().items():\n",
    "    print(key)\n",
    "    # print(val)\n",
    "    # print(left.blocks()[key])\n",
    "    print((val-left.blocks()[key]).norm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1, 0) ((4, 4), (4, 4), (2, 2)) (1, 0, 1) ((4, 4), (4, 4), (2, 2))\n"
     ]
    }
   ],
   "source": [
    "# test one-site solver\n",
    "\n",
    "m_dual = (0, 1, 0)\n",
    "m_shape = (4, 4), (4, 4), (2, 2)\n",
    "a_shape = (3, 3), (3, 3), (2, 2)\n",
    "a_whole_shape = tuple([sum(x) for x in a_shape])\n",
    "\n",
    "def fidelty(m, a, le, re):\n",
    "\n",
    "    x = tp.gcontract('abc,ad,be,dec->', m.conj(), le.conj(reverse=True), re.conj(reverse=True), a)\n",
    "    y = tp.gcontract('abc,ad,be,dec->', a.conj(), le, re, m)\n",
    "\n",
    "    return x*y\n",
    "\n",
    "def solver(m, le, re):\n",
    "\n",
    "    def mv(v):\n",
    "        tv = torch.from_numpy(v.reshape(a_whole_shape)).cdouble()\n",
    "        gtv = GTensor.extract_blocks(tv, m_dual, a_shape)\n",
    "        temp = tp.gcontract('abc,ad,be,dec->', m.conj(), le.conj(reverse=True), re.conj(reverse=True), gtv)\n",
    "        w = temp*tp.gcontract('ad,be,dec->abc', le, re, m)\n",
    "\n",
    "        return w.push_blocks().numpy().flatten()\n",
    "    \n",
    "    dim_op = math.prod(a_whole_shape)\n",
    "    op = scipy.sparse.linalg.LinearOperator(shape=(dim_op, dim_op), matvec=mv)\n",
    "    v_init = GTensor.rand(dual=m_dual, shape=a_shape).push_blocks().numpy().flatten()\n",
    "    # print(v_init.shape, dim_op)\n",
    "    vals, vecs = scipy.sparse.linalg.eigsh(\n",
    "        op, k=3, which='LA', v0=v_init, maxiter=None, return_eigenvectors=True)\n",
    "    inds = np.real(vals).argsort()[::-1]\n",
    "    sorted_vals, sorted_vecs = vals[inds], vecs[:, inds]\n",
    "    print(sorted_vals)\n",
    "\n",
    "    lam = sorted_vals[0]\n",
    "    eig_v = sorted_vecs[:, 0]\n",
    "    eig_vt = torch.from_numpy(eig_v.reshape(a_whole_shape))\n",
    "    eig_gvt = GTensor.extract_blocks(eig_vt, m_dual, a_shape)\n",
    "\n",
    "    return lam, eig_gvt\n",
    "\n",
    "m = GTensor.rand(dual=m_dual, shape=m_shape, cflag=True)\n",
    "a = GTensor.rand(dual=m_dual, shape=a_shape, cflag=True)\n",
    "\n",
    "m_dagger = m.conj()\n",
    "print(m.dual, m.shape, m_dagger.dual, m_dagger.shape)\n",
    "\n",
    "le = GTensor.rand(dual=(0, 1), shape=(a_shape[0], m_shape[0]), cflag=True)\n",
    "re = GTensor.rand(dual=(1, 0), shape=(a_shape[1], m_shape[1]), cflag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.82857674e-14 1.07737034e-14 1.06133329e-14]\n",
      "tensor(61130.77253+6.43979e-12j) tensor(9.46633e-30+2.36658e-30j)\n"
     ]
    }
   ],
   "source": [
    "lam, b = solver(m, le, re)\n",
    "print(fidelty(m, a, le, re), fidelty(m, b, le, re))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test MPS compression\n",
    "num = 8\n",
    "D = 8\n",
    "gt_dual = (0, 1, 0)\n",
    "ref_fmps = fMPS.rand_obc(n=num, dual=gt_dual, max_shape=(D // 2, D // 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(mps_0, mps_1):\n",
    "    print(mps_0.inner_product(mps_0.dagger(), mps_1), mps_0.inner_product(mps_1.dagger(), mps_0))\n",
    "    return mps_0.inner_product(mps_0.dagger(), mps_1)*mps_0.inner_product(mps_1.dagger(), mps_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "super(type, obj): obj must be an instance or subtype of type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/wei/Documents/physics/code/tnpy/notebooks/fermionic_MPS.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/wei/Documents/physics/code/tnpy/notebooks/fermionic_MPS.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m D \u001b[39m=\u001b[39m \u001b[39m4\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/wei/Documents/physics/code/tnpy/notebooks/fermionic_MPS.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m fmps \u001b[39m=\u001b[39m fMPS\u001b[39m.\u001b[39;49mrand_obc(n\u001b[39m=\u001b[39;49mnum, dual\u001b[39m=\u001b[39;49mgt_dual, max_shape\u001b[39m=\u001b[39;49m(D \u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m \u001b[39m2\u001b[39;49m, D \u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m \u001b[39m2\u001b[39;49m))\u001b[39m.\u001b[39mleft_canonical()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/wei/Documents/physics/code/tnpy/notebooks/fermionic_MPS.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, gt \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(fmps\u001b[39m.\u001b[39mtensors):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/wei/Documents/physics/code/tnpy/notebooks/fermionic_MPS.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mprint\u001b[39m(i, gt\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/Documents/physics/code/tnpy/tnpy/mps/fermi_finite_mps.py:87\u001b[0m, in \u001b[0;36mFermiMPS.rand_obc\u001b[0;34m(cls, n, dual, max_shape, cflag)\u001b[0m\n\u001b[1;32m     85\u001b[0m         dim_beta \u001b[39m=\u001b[39m  \u001b[39mmin\u001b[39m(dim_phys\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m(n\u001b[39m-\u001b[39mi\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), max_shape[\u001b[39m0\u001b[39m]), \u001b[39mmin\u001b[39m(dim_phys\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m(n\u001b[39m-\u001b[39mi\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), max_shape[\u001b[39m1\u001b[39m])\n\u001b[1;32m     86\u001b[0m         gt_shape \u001b[39m=\u001b[39m dim_alpha, dim_beta, (\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[0;32m---> 87\u001b[0m     gts\u001b[39m.\u001b[39mappend(GTensor\u001b[39m.\u001b[39;49mrand(dual, shape\u001b[39m=\u001b[39;49mgt_shape, cflag\u001b[39m=\u001b[39;49mcflag))\n\u001b[1;32m     89\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m(gts)\n",
      "File \u001b[0;32m~/Documents/physics/code/tnpy/tnpy/fermi_tensor.py:603\u001b[0m, in \u001b[0;36mGTensor.rand\u001b[0;34m(cls, dual, shape, cflag, info)\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    601\u001b[0m             blocks[q] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrand(block_shape)\n\u001b[0;32m--> 603\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(dual, shape, blocks, cflag, info)\n",
      "File \u001b[0;32m~/Documents/physics/code/tnpy/tnpy/fermi_tensor.py:465\u001b[0m, in \u001b[0;36mGTensor.__init__\u001b[0;34m(self, dual, shape, blocks, cflag, info)\u001b[0m\n\u001b[1;32m    462\u001b[0m         block_shape \u001b[39m=\u001b[39m [shape[i][v] \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(qs)]\n\u001b[1;32m    463\u001b[0m         blocks[qs] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(block_shape)\n\u001b[0;32m--> 465\u001b[0m \u001b[39msuper\u001b[39;49m(GTensor, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(dual, shape, blocks, cflag, info)\n\u001b[1;32m    466\u001b[0m \u001b[39m# check the dual\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rank[\u001b[39m0\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rank[\u001b[39m1\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mGTensor must have both outgoing and incoming bonds\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: super(type, obj): obj must be an instance or subtype of type"
     ]
    }
   ],
   "source": [
    "D = 4\n",
    "fmps = fMPS.rand_obc(n=num, dual=gt_dual, max_shape=(D // 2, D // 2)).left_canonical()\n",
    "\n",
    "for i, gt in enumerate(fmps.tensors):\n",
    "    print(i, gt.shape)\n",
    "\n",
    "# test its inner product\n",
    "print(fmps.inner_product(fmps.dagger(), fmps))\n",
    "print(fmps.inner_product(fmps, fmps.dagger()))\n",
    "\n",
    "print(fmps.inner_product(fmps.dagger(), ref_fmps))\n",
    "print(fmps.inner_product(ref_fmps.dagger(), fmps))\n",
    "\n",
    "print('test', test(fmps, ref_fmps).item())\n",
    "print('test', test(ref_fmps, fmps).item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
